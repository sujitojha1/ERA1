{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sujitojha1/ERA1/blob/main/Session21/ERA1_Session21_nanoGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zhzu8JxoU_De"
      },
      "source": [
        "## Load Models & Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "TlNFXiUCQgIh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf2d35f4-0615-45bc-98d7-e8f6b4512f1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6q7-hicVB8I",
        "outputId": "b2753fc1-3c1d-48f6-bfca-7a4e386946aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot move 'ERA1/Session21/data' to './data': Directory not empty\n",
            "Loaded Modules and Models\n"
          ]
        }
      ],
      "source": [
        "# Future print function\n",
        "from __future__ import print_function\n",
        "\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Load modules/models from EVA course\n",
        "!git clone https://github.com/sujitojha1/ERA1 -q --quiet\n",
        "!mv ERA1/Session21/* .\n",
        "!rm -rf ERA1\n",
        "\n",
        "print(\"Loaded Modules and Models\")\n",
        "\n",
        "# # Installing latest Albumentation library\n",
        "# !pip install -U git+https://github.com/albu/albumentations -q --quiet\n",
        "# !pip install torch-lr-finder -q --quiet\n",
        "# !pip install grad-cam -q --quiet\n",
        "# !pip install --quiet \"pandas\" \"ipython[notebook]\" \"seaborn\" \"pytorch-lightning\" \"torchmetrics\" \"lightning-bolts\"\n",
        "!pip install -q --quiet datasets tiktoken tqdm\n",
        "\n",
        "# For inline matplotlib plotting\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "no3QZDSKkbnM"
      },
      "outputs": [],
      "source": [
        "from data.shakespeare import prepare"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py train_shakespeare_char.py"
      ],
      "metadata": {
        "id": "aULcEKJhgude",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1f94418-cf22-48b9-fa3a-e1a6e5e681d5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding config with train_shakespeare_char.py:\n",
            "# train a miniature character-level shakespeare model\n",
            "# good for debugging and playing on macbooks and such\n",
            "\n",
            "out_dir = 'out-shakespeare'\n",
            "eval_interval = 250 # keep frequent because we'll overfit\n",
            "eval_iters = 200\n",
            "log_interval = 10 # don't print too too often\n",
            "\n",
            "# we expect to overfit on this small dataset, so only save when val improves\n",
            "always_save_checkpoint = False\n",
            "\n",
            "wandb_log = False # override via command line if you like\n",
            "wandb_project = 'shakespeare-char'\n",
            "wandb_run_name = 'mini-gpt'\n",
            "\n",
            "dataset = 'shakespeare'\n",
            "gradient_accumulation_steps = 1\n",
            "batch_size = 64\n",
            "block_size = 256 # context of up to 256 previous characters\n",
            "\n",
            "# baby GPT model :)\n",
            "n_layer = 6\n",
            "n_head = 6\n",
            "n_embd = 384\n",
            "dropout = 0.2\n",
            "\n",
            "learning_rate = 1e-3 # with baby networks can afford to go a bit higher\n",
            "max_iters = 5000\n",
            "lr_decay_iters = 5000 # make equal to max_iters usually\n",
            "min_lr = 1e-4 # learning_rate / 10 usually\n",
            "beta2 = 0.99 # make a bit bigger because number of tokens per iter is small\n",
            "\n",
            "warmup_iters = 100 # not super necessary potentially\n",
            "\n",
            "# on macbook also add\n",
            "# device = 'cpu'  # run on cpu only\n",
            "# compile = False # do not torch compile the model\n",
            "tokens per iteration will be: 16,384\n",
            "Initializing a new model from scratch\n",
            "defaulting to vocab_size of GPT-2 to 50304 (50257 rounded up for efficiency)\n",
            "number of parameters: 29.94M\n",
            "num decayed parameter tensors: 26, with 30,031,872 parameters\n",
            "num non-decayed parameter tensors: 13, with 4,992 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 10.8995, val loss 10.8946\n",
            "iter 0: loss 10.9011, time 46806.72ms, mfu -100.00%\n",
            "iter 10: loss 9.7444, time 337.03ms, mfu 2.91%\n",
            "iter 20: loss 8.9319, time 337.62ms, mfu 2.91%\n",
            "iter 30: loss 7.6917, time 337.37ms, mfu 2.91%\n",
            "iter 40: loss 6.5715, time 329.82ms, mfu 2.91%\n",
            "iter 50: loss 6.0352, time 346.76ms, mfu 2.91%\n",
            "iter 60: loss 5.7995, time 340.29ms, mfu 2.90%\n",
            "iter 70: loss 5.5872, time 340.50ms, mfu 2.90%\n",
            "iter 80: loss 5.3542, time 361.29ms, mfu 2.88%\n",
            "iter 90: loss 5.1773, time 339.93ms, mfu 2.88%\n",
            "iter 100: loss 5.0249, time 346.98ms, mfu 2.88%\n",
            "iter 110: loss 4.8187, time 349.30ms, mfu 2.87%\n",
            "iter 120: loss 4.6682, time 357.87ms, mfu 2.86%\n",
            "iter 130: loss 4.5615, time 349.80ms, mfu 2.85%\n",
            "iter 140: loss 4.5852, time 343.22ms, mfu 2.85%\n",
            "iter 150: loss 4.4896, time 340.02ms, mfu 2.86%\n",
            "iter 160: loss 4.4689, time 339.63ms, mfu 2.86%\n",
            "iter 170: loss 4.3219, time 344.33ms, mfu 2.86%\n",
            "iter 180: loss 4.2465, time 339.98ms, mfu 2.86%\n",
            "iter 190: loss 4.1818, time 340.57ms, mfu 2.86%\n",
            "iter 200: loss 4.1769, time 331.64ms, mfu 2.87%\n",
            "iter 210: loss 4.0796, time 337.27ms, mfu 2.87%\n",
            "iter 220: loss 4.0107, time 341.49ms, mfu 2.87%\n",
            "iter 230: loss 4.0078, time 338.36ms, mfu 2.88%\n",
            "iter 240: loss 3.9196, time 334.72ms, mfu 2.88%\n",
            "step 250: train loss 3.8260, val loss 4.8739\n",
            "saving checkpoint to out-shakespeare\n",
            "iter 250: loss 3.9559, time 49722.39ms, mfu 2.60%\n",
            "iter 260: loss 3.8103, time 333.83ms, mfu 2.63%\n",
            "iter 270: loss 3.7709, time 335.63ms, mfu 2.66%\n",
            "iter 280: loss 3.7503, time 334.52ms, mfu 2.69%\n",
            "iter 290: loss 3.7272, time 333.05ms, mfu 2.71%\n",
            "iter 300: loss 3.7477, time 333.50ms, mfu 2.73%\n",
            "iter 310: loss 3.7991, time 342.35ms, mfu 2.75%\n",
            "iter 320: loss 3.5705, time 337.13ms, mfu 2.76%\n",
            "iter 330: loss 3.5637, time 339.89ms, mfu 2.78%\n",
            "iter 340: loss 3.5579, time 336.26ms, mfu 2.79%\n",
            "iter 350: loss 3.4656, time 341.02ms, mfu 2.80%\n",
            "iter 360: loss 3.4638, time 346.29ms, mfu 2.80%\n",
            "iter 370: loss 3.4611, time 342.07ms, mfu 2.81%\n",
            "iter 380: loss 3.3938, time 342.82ms, mfu 2.81%\n",
            "iter 390: loss 3.4037, time 352.10ms, mfu 2.81%\n",
            "iter 400: loss 3.3126, time 354.29ms, mfu 2.81%\n",
            "iter 410: loss 3.2867, time 342.22ms, mfu 2.81%\n",
            "iter 420: loss 3.1625, time 328.62ms, mfu 2.83%\n",
            "iter 430: loss 3.2739, time 341.63ms, mfu 2.83%\n",
            "iter 440: loss 3.1547, time 345.70ms, mfu 2.83%\n",
            "iter 450: loss 3.2172, time 334.81ms, mfu 2.84%\n",
            "iter 460: loss 3.0835, time 338.65ms, mfu 2.85%\n",
            "iter 470: loss 3.0852, time 328.06ms, mfu 2.86%\n",
            "iter 480: loss 3.0984, time 335.49ms, mfu 2.87%\n",
            "iter 490: loss 2.8995, time 341.55ms, mfu 2.87%\n",
            "step 500: train loss 2.7560, val loss 5.0754\n",
            "iter 500: loss 3.0553, time 46736.04ms, mfu 2.58%\n",
            "iter 510: loss 2.8793, time 335.82ms, mfu 2.62%\n",
            "iter 520: loss 2.9556, time 330.09ms, mfu 2.65%\n",
            "iter 530: loss 2.8392, time 336.65ms, mfu 2.68%\n",
            "iter 540: loss 2.8850, time 338.78ms, mfu 2.70%\n",
            "iter 550: loss 2.7554, time 340.01ms, mfu 2.72%\n",
            "iter 560: loss 2.7771, time 335.31ms, mfu 2.74%\n",
            "iter 570: loss 2.7683, time 337.37ms, mfu 2.76%\n",
            "iter 580: loss 2.7060, time 332.29ms, mfu 2.78%\n",
            "iter 590: loss 2.7999, time 331.69ms, mfu 2.79%\n",
            "iter 600: loss 2.6553, time 338.42ms, mfu 2.80%\n",
            "iter 610: loss 2.7717, time 334.05ms, mfu 2.82%\n",
            "iter 620: loss 2.6460, time 337.20ms, mfu 2.83%\n",
            "iter 630: loss 2.5362, time 332.92ms, mfu 2.84%\n",
            "iter 640: loss 2.5579, time 340.58ms, mfu 2.84%\n",
            "iter 650: loss 2.4313, time 330.86ms, mfu 2.85%\n",
            "iter 660: loss 2.5061, time 338.00ms, mfu 2.86%\n",
            "iter 670: loss 2.3920, time 329.92ms, mfu 2.87%\n",
            "iter 680: loss 2.4011, time 333.07ms, mfu 2.88%\n",
            "iter 690: loss 2.4986, time 334.96ms, mfu 2.88%\n",
            "iter 700: loss 2.3932, time 332.62ms, mfu 2.89%\n",
            "iter 710: loss 2.2578, time 337.49ms, mfu 2.89%\n",
            "iter 720: loss 2.2930, time 337.37ms, mfu 2.89%\n",
            "iter 730: loss 2.3217, time 334.29ms, mfu 2.90%\n",
            "iter 740: loss 2.2572, time 335.86ms, mfu 2.90%\n",
            "step 750: train loss 1.7385, val loss 5.6510\n",
            "iter 750: loss 2.1525, time 46915.00ms, mfu 2.61%\n",
            "iter 760: loss 2.2292, time 336.99ms, mfu 2.64%\n",
            "iter 770: loss 2.1800, time 336.14ms, mfu 2.67%\n",
            "iter 780: loss 2.1351, time 339.55ms, mfu 2.69%\n",
            "iter 790: loss 2.1295, time 335.28ms, mfu 2.71%\n",
            "iter 800: loss 2.0762, time 330.76ms, mfu 2.74%\n",
            "iter 810: loss 1.9707, time 330.63ms, mfu 2.76%\n",
            "iter 820: loss 1.9502, time 334.48ms, mfu 2.78%\n",
            "iter 830: loss 1.9956, time 333.50ms, mfu 2.79%\n",
            "iter 840: loss 2.0094, time 337.08ms, mfu 2.81%\n",
            "iter 850: loss 1.9272, time 330.16ms, mfu 2.82%\n",
            "iter 860: loss 1.9925, time 334.85ms, mfu 2.83%\n",
            "iter 870: loss 1.9213, time 336.00ms, mfu 2.84%\n",
            "iter 880: loss 1.8661, time 332.40ms, mfu 2.85%\n",
            "iter 890: loss 1.8164, time 334.06ms, mfu 2.86%\n",
            "iter 900: loss 1.7888, time 337.68ms, mfu 2.86%\n",
            "iter 920: loss 1.7353, time 327.69ms, mfu 2.89%\n",
            "iter 930: loss 1.6548, time 329.01ms, mfu 2.90%\n",
            "iter 940: loss 1.7507, time 333.29ms, mfu 2.90%\n",
            "iter 950: loss 1.7270, time 332.13ms, mfu 2.91%\n",
            "iter 960: loss 1.6438, time 332.35ms, mfu 2.91%\n",
            "iter 970: loss 1.6583, time 336.49ms, mfu 2.91%\n",
            "iter 980: loss 1.5793, time 333.44ms, mfu 2.91%\n",
            "iter 990: loss 1.6471, time 334.58ms, mfu 2.91%\n",
            "step 1000: train loss 0.9750, val loss 6.2778\n",
            "iter 1000: loss 1.5508, time 47113.14ms, mfu 2.63%\n",
            "iter 1010: loss 1.5714, time 333.33ms, mfu 2.66%\n",
            "iter 1020: loss 1.5115, time 333.19ms, mfu 2.69%\n",
            "iter 1030: loss 1.5029, time 336.18ms, mfu 2.71%\n",
            "iter 1040: loss 1.5017, time 332.99ms, mfu 2.73%\n",
            "iter 1050: loss 1.4301, time 332.81ms, mfu 2.75%\n",
            "iter 1060: loss 1.4348, time 335.76ms, mfu 2.77%\n",
            "iter 1070: loss 1.3542, time 332.67ms, mfu 2.79%\n",
            "iter 1080: loss 1.3884, time 330.72ms, mfu 2.81%\n",
            "iter 1090: loss 1.3685, time 328.32ms, mfu 2.82%\n",
            "iter 1100: loss 1.3307, time 331.12ms, mfu 2.84%\n",
            "iter 1110: loss 1.3594, time 329.87ms, mfu 2.85%\n",
            "iter 1120: loss 1.3748, time 333.15ms, mfu 2.86%\n",
            "iter 1130: loss 1.3207, time 326.98ms, mfu 2.87%\n",
            "iter 1140: loss 1.2348, time 332.01ms, mfu 2.88%\n",
            "iter 1150: loss 1.2620, time 329.74ms, mfu 2.89%\n",
            "iter 1160: loss 1.2517, time 332.73ms, mfu 2.90%\n",
            "iter 1170: loss 1.3009, time 331.07ms, mfu 2.90%\n",
            "iter 1180: loss 1.2077, time 330.83ms, mfu 2.91%\n",
            "iter 1190: loss 1.2519, time 330.60ms, mfu 2.91%\n",
            "iter 1200: loss 1.2272, time 333.17ms, mfu 2.92%\n",
            "iter 1210: loss 1.2076, time 326.61ms, mfu 2.93%\n",
            "iter 1220: loss 1.1830, time 333.77ms, mfu 2.93%\n",
            "iter 1230: loss 1.1343, time 330.75ms, mfu 2.93%\n",
            "iter 1240: loss 1.1875, time 335.45ms, mfu 2.93%\n",
            "step 1250: train loss 0.5448, val loss 6.8865\n",
            "iter 1250: loss 1.2030, time 47037.25ms, mfu 2.64%\n",
            "iter 1260: loss 1.0906, time 334.46ms, mfu 2.67%\n",
            "iter 1270: loss 1.1499, time 328.85ms, mfu 2.70%\n",
            "iter 1280: loss 1.1441, time 332.31ms, mfu 2.72%\n",
            "iter 1290: loss 1.0674, time 328.11ms, mfu 2.75%\n",
            "iter 1300: loss 1.0846, time 330.49ms, mfu 2.77%\n",
            "iter 1310: loss 1.0962, time 329.56ms, mfu 2.79%\n",
            "iter 1320: loss 1.0410, time 331.91ms, mfu 2.81%\n",
            "iter 1330: loss 1.1031, time 332.84ms, mfu 2.82%\n",
            "iter 1340: loss 1.0420, time 332.51ms, mfu 2.84%\n",
            "iter 1350: loss 0.9967, time 331.22ms, mfu 2.85%\n",
            "iter 1360: loss 1.0392, time 331.47ms, mfu 2.86%\n",
            "iter 1370: loss 0.9911, time 329.93ms, mfu 2.87%\n",
            "iter 1380: loss 1.0618, time 332.88ms, mfu 2.88%\n",
            "iter 1390: loss 0.9688, time 330.33ms, mfu 2.89%\n",
            "iter 1400: loss 0.9466, time 327.02ms, mfu 2.90%\n",
            "iter 1410: loss 1.0165, time 330.60ms, mfu 2.90%\n",
            "iter 1420: loss 0.9435, time 327.50ms, mfu 2.91%\n",
            "iter 1430: loss 0.9177, time 329.68ms, mfu 2.92%\n",
            "iter 1440: loss 0.9233, time 329.42ms, mfu 2.93%\n",
            "iter 1450: loss 0.8847, time 327.55ms, mfu 2.93%\n",
            "iter 1460: loss 0.8790, time 330.56ms, mfu 2.94%\n",
            "iter 1470: loss 0.8839, time 328.87ms, mfu 2.94%\n",
            "iter 1480: loss 0.9145, time 327.39ms, mfu 2.95%\n",
            "iter 1490: loss 0.8947, time 330.85ms, mfu 2.95%\n",
            "step 1500: train loss 0.3468, val loss 7.4152\n",
            "iter 1500: loss 0.8128, time 47011.50ms, mfu 2.65%\n",
            "iter 1510: loss 0.8329, time 329.80ms, mfu 2.69%\n",
            "iter 1520: loss 0.8776, time 331.57ms, mfu 2.71%\n",
            "iter 1530: loss 0.8014, time 328.93ms, mfu 2.74%\n",
            "iter 1540: loss 0.8384, time 329.48ms, mfu 2.76%\n",
            "iter 1550: loss 0.8196, time 330.25ms, mfu 2.78%\n",
            "iter 1560: loss 0.7873, time 329.40ms, mfu 2.80%\n",
            "iter 1570: loss 0.8239, time 328.74ms, mfu 2.82%\n",
            "iter 1580: loss 0.8014, time 330.27ms, mfu 2.84%\n",
            "iter 1590: loss 0.7948, time 329.15ms, mfu 2.85%\n",
            "iter 1600: loss 0.7608, time 334.05ms, mfu 2.86%\n",
            "iter 1610: loss 0.7858, time 330.72ms, mfu 2.87%\n",
            "iter 1620: loss 0.8252, time 329.65ms, mfu 2.88%\n",
            "iter 1630: loss 0.7746, time 327.00ms, mfu 2.89%\n",
            "iter 1640: loss 0.7299, time 323.13ms, mfu 2.91%\n",
            "iter 1650: loss 0.7710, time 329.95ms, mfu 2.91%\n",
            "iter 1660: loss 0.7188, time 328.40ms, mfu 2.92%\n",
            "iter 1670: loss 0.7770, time 328.63ms, mfu 2.93%\n",
            "iter 1680: loss 0.7547, time 328.08ms, mfu 2.93%\n",
            "iter 1690: loss 0.7427, time 328.78ms, mfu 2.94%\n",
            "iter 1700: loss 0.7495, time 328.72ms, mfu 2.94%\n",
            "iter 1710: loss 0.7409, time 328.69ms, mfu 2.95%\n",
            "iter 1720: loss 0.7564, time 330.50ms, mfu 2.95%\n",
            "iter 1730: loss 0.7144, time 330.35ms, mfu 2.95%\n",
            "iter 1740: loss 0.6879, time 327.63ms, mfu 2.95%\n",
            "step 1750: train loss 0.2489, val loss 7.7566\n",
            "iter 1750: loss 0.6982, time 47114.41ms, mfu 2.66%\n",
            "iter 1760: loss 0.6894, time 327.51ms, mfu 2.69%\n",
            "iter 1770: loss 0.7121, time 326.33ms, mfu 2.73%\n",
            "iter 1780: loss 0.6890, time 328.80ms, mfu 2.75%\n",
            "iter 1790: loss 0.6967, time 329.63ms, mfu 2.77%\n",
            "iter 1800: loss 0.6555, time 327.35ms, mfu 2.80%\n",
            "iter 1810: loss 0.6716, time 330.81ms, mfu 2.81%\n",
            "iter 1820: loss 0.6519, time 328.82ms, mfu 2.83%\n",
            "iter 1830: loss 0.6385, time 327.35ms, mfu 2.85%\n",
            "iter 1840: loss 0.6474, time 328.45ms, mfu 2.86%\n",
            "iter 1850: loss 0.6353, time 327.22ms, mfu 2.87%\n",
            "iter 1860: loss 0.6249, time 328.38ms, mfu 2.88%\n",
            "iter 1870: loss 0.6353, time 328.08ms, mfu 2.90%\n",
            "iter 1880: loss 0.6484, time 329.62ms, mfu 2.90%\n",
            "iter 1890: loss 0.6291, time 329.99ms, mfu 2.91%\n",
            "iter 1900: loss 0.6218, time 330.17ms, mfu 2.92%\n",
            "iter 1910: loss 0.6179, time 329.82ms, mfu 2.92%\n",
            "iter 1920: loss 0.6098, time 329.51ms, mfu 2.93%\n",
            "iter 1930: loss 0.6198, time 329.08ms, mfu 2.93%\n",
            "iter 1940: loss 0.6267, time 327.15ms, mfu 2.94%\n",
            "iter 1950: loss 0.6097, time 326.51ms, mfu 2.95%\n",
            "iter 1960: loss 0.5873, time 325.77ms, mfu 2.95%\n",
            "iter 1970: loss 0.6021, time 327.96ms, mfu 2.96%\n",
            "iter 1980: loss 0.5910, time 331.62ms, mfu 2.96%\n",
            "iter 1990: loss 0.5841, time 328.52ms, mfu 2.96%\n",
            "step 2000: train loss 0.1889, val loss 8.1051\n",
            "iter 2000: loss 0.5999, time 47112.65ms, mfu 2.66%\n",
            "iter 2010: loss 0.5874, time 328.56ms, mfu 2.70%\n",
            "iter 2020: loss 0.5954, time 329.04ms, mfu 2.72%\n",
            "iter 2030: loss 0.5787, time 330.41ms, mfu 2.75%\n",
            "iter 2040: loss 0.5467, time 330.34ms, mfu 2.77%\n",
            "iter 2050: loss 0.5717, time 326.27ms, mfu 2.79%\n",
            "iter 2060: loss 0.5622, time 328.12ms, mfu 2.81%\n",
            "iter 2070: loss 0.5760, time 329.46ms, mfu 2.83%\n",
            "iter 2080: loss 0.5592, time 327.97ms, mfu 2.85%\n",
            "iter 2090: loss 0.5575, time 328.59ms, mfu 2.86%\n",
            "iter 2100: loss 0.5565, time 330.03ms, mfu 2.87%\n",
            "iter 2110: loss 0.5137, time 325.76ms, mfu 2.88%\n",
            "iter 2120: loss 0.5424, time 327.59ms, mfu 2.90%\n",
            "iter 2130: loss 0.5268, time 329.05ms, mfu 2.90%\n",
            "iter 2140: loss 0.5307, time 329.97ms, mfu 2.91%\n",
            "iter 2150: loss 0.5224, time 326.53ms, mfu 2.92%\n",
            "iter 2160: loss 0.5624, time 330.58ms, mfu 2.92%\n",
            "iter 2170: loss 0.5632, time 327.24ms, mfu 2.93%\n",
            "iter 2180: loss 0.5142, time 324.75ms, mfu 2.94%\n",
            "iter 2190: loss 0.5102, time 326.70ms, mfu 2.95%\n",
            "iter 2200: loss 0.5147, time 329.53ms, mfu 2.95%\n",
            "iter 2210: loss 0.5057, time 326.47ms, mfu 2.95%\n",
            "iter 2220: loss 0.5131, time 329.32ms, mfu 2.96%\n",
            "iter 2230: loss 0.4944, time 327.51ms, mfu 2.96%\n",
            "iter 2240: loss 0.4920, time 326.73ms, mfu 2.96%\n",
            "step 2250: train loss 0.1571, val loss 8.3748\n",
            "iter 2250: loss 0.5088, time 47127.22ms, mfu 2.67%\n",
            "iter 2260: loss 0.5144, time 331.27ms, mfu 2.70%\n",
            "iter 2270: loss 0.4930, time 327.99ms, mfu 2.73%\n",
            "iter 2280: loss 0.4723, time 329.53ms, mfu 2.75%\n",
            "iter 2290: loss 0.4761, time 330.04ms, mfu 2.77%\n",
            "iter 2300: loss 0.4864, time 330.03ms, mfu 2.79%\n",
            "iter 2310: loss 0.4992, time 328.36ms, mfu 2.81%\n",
            "iter 2320: loss 0.4949, time 326.48ms, mfu 2.83%\n",
            "iter 2330: loss 0.4788, time 327.53ms, mfu 2.85%\n",
            "iter 2340: loss 0.4713, time 329.39ms, mfu 2.86%\n",
            "iter 2350: loss 0.4811, time 328.39ms, mfu 2.87%\n",
            "iter 2360: loss 0.4553, time 326.57ms, mfu 2.89%\n",
            "iter 2370: loss 0.4597, time 325.96ms, mfu 2.90%\n",
            "iter 2380: loss 0.4596, time 329.23ms, mfu 2.91%\n",
            "iter 2390: loss 0.4825, time 329.39ms, mfu 2.91%\n",
            "iter 2400: loss 0.4440, time 327.31ms, mfu 2.92%\n",
            "iter 2410: loss 0.4559, time 330.23ms, mfu 2.93%\n",
            "iter 2420: loss 0.4778, time 326.80ms, mfu 2.93%\n",
            "iter 2430: loss 0.4160, time 327.74ms, mfu 2.94%\n",
            "iter 2440: loss 0.4323, time 327.11ms, mfu 2.95%\n",
            "iter 2450: loss 0.4196, time 330.50ms, mfu 2.95%\n",
            "iter 2460: loss 0.4514, time 331.57ms, mfu 2.95%\n",
            "iter 2470: loss 0.4791, time 328.18ms, mfu 2.95%\n",
            "iter 2480: loss 0.4280, time 328.34ms, mfu 2.96%\n",
            "iter 2490: loss 0.4225, time 326.15ms, mfu 2.96%\n",
            "step 2500: train loss 0.1376, val loss 8.5637\n",
            "iter 2500: loss 0.4171, time 47174.63ms, mfu 2.67%\n",
            "iter 2510: loss 0.3978, time 329.12ms, mfu 2.70%\n",
            "iter 2520: loss 0.3993, time 328.36ms, mfu 2.73%\n",
            "iter 2530: loss 0.4279, time 328.81ms, mfu 2.75%\n",
            "iter 2540: loss 0.3906, time 326.70ms, mfu 2.78%\n",
            "iter 2550: loss 0.4181, time 324.65ms, mfu 2.80%\n",
            "iter 2560: loss 0.4142, time 329.78ms, mfu 2.82%\n",
            "iter 2570: loss 0.3952, time 329.89ms, mfu 2.83%\n",
            "iter 2580: loss 0.4184, time 330.75ms, mfu 2.85%\n",
            "iter 2590: loss 0.4367, time 332.06ms, mfu 2.86%\n",
            "iter 2600: loss 0.4043, time 329.88ms, mfu 2.87%\n",
            "iter 2610: loss 0.4124, time 327.94ms, mfu 2.88%\n",
            "iter 2620: loss 0.3953, time 329.97ms, mfu 2.89%\n",
            "iter 2630: loss 0.4008, time 330.22ms, mfu 2.90%\n",
            "iter 2640: loss 0.3644, time 328.45ms, mfu 2.91%\n",
            "iter 2650: loss 0.4122, time 325.42ms, mfu 2.92%\n",
            "iter 2660: loss 0.4065, time 325.30ms, mfu 2.93%\n",
            "iter 2670: loss 0.3846, time 326.98ms, mfu 2.93%\n",
            "iter 2680: loss 0.3913, time 328.23ms, mfu 2.94%\n",
            "iter 2690: loss 0.3588, time 325.00ms, mfu 2.95%\n",
            "iter 2700: loss 0.3774, time 332.02ms, mfu 2.95%\n",
            "iter 2710: loss 0.3854, time 327.78ms, mfu 2.95%\n",
            "iter 2720: loss 0.3731, time 324.37ms, mfu 2.96%\n",
            "iter 2730: loss 0.3722, time 331.51ms, mfu 2.96%\n",
            "iter 2740: loss 0.3684, time 327.83ms, mfu 2.96%\n",
            "step 2750: train loss 0.1232, val loss 8.7963\n",
            "iter 2750: loss 0.3713, time 47083.43ms, mfu 2.67%\n",
            "iter 2760: loss 0.3687, time 332.53ms, mfu 2.70%\n",
            "iter 2770: loss 0.3781, time 329.07ms, mfu 2.72%\n",
            "iter 2780: loss 0.3542, time 327.92ms, mfu 2.75%\n",
            "iter 2790: loss 0.3507, time 331.32ms, mfu 2.77%\n",
            "iter 2800: loss 0.3642, time 326.90ms, mfu 2.79%\n",
            "iter 2810: loss 0.3606, time 326.21ms, mfu 2.82%\n",
            "iter 2820: loss 0.3520, time 327.67ms, mfu 2.83%\n",
            "iter 2830: loss 0.3716, time 330.06ms, mfu 2.85%\n",
            "iter 2840: loss 0.3642, time 325.67ms, mfu 2.86%\n",
            "iter 2850: loss 0.3669, time 324.89ms, mfu 2.88%\n",
            "iter 2860: loss 0.3584, time 329.12ms, mfu 2.89%\n",
            "iter 2870: loss 0.3552, time 326.29ms, mfu 2.90%\n",
            "iter 2880: loss 0.3544, time 327.72ms, mfu 2.91%\n",
            "iter 2890: loss 0.3600, time 326.45ms, mfu 2.92%\n",
            "iter 2900: loss 0.3410, time 327.48ms, mfu 2.93%\n",
            "iter 2910: loss 0.3520, time 326.27ms, mfu 2.93%\n",
            "iter 2920: loss 0.3351, time 327.98ms, mfu 2.94%\n",
            "iter 2930: loss 0.3555, time 328.01ms, mfu 2.94%\n",
            "iter 2940: loss 0.3424, time 325.82ms, mfu 2.95%\n",
            "iter 2950: loss 0.3454, time 327.20ms, mfu 2.96%\n",
            "iter 2960: loss 0.3411, time 331.26ms, mfu 2.96%\n",
            "iter 2970: loss 0.3375, time 326.49ms, mfu 2.96%\n",
            "iter 2980: loss 0.3261, time 328.32ms, mfu 2.96%\n",
            "iter 2990: loss 0.3386, time 323.79ms, mfu 2.97%\n",
            "step 3000: train loss 0.1139, val loss 8.9413\n",
            "iter 3000: loss 0.3412, time 47161.09ms, mfu 2.67%\n",
            "iter 3010: loss 0.3253, time 329.38ms, mfu 2.71%\n",
            "iter 3020: loss 0.3180, time 326.19ms, mfu 2.74%\n",
            "iter 3030: loss 0.3329, time 331.87ms, mfu 2.76%\n",
            "iter 3040: loss 0.3292, time 326.70ms, mfu 2.78%\n",
            "iter 3050: loss 0.3330, time 324.90ms, mfu 2.81%\n",
            "iter 3060: loss 0.3170, time 327.22ms, mfu 2.82%\n",
            "iter 3070: loss 0.3293, time 328.87ms, mfu 2.84%\n",
            "iter 3080: loss 0.3164, time 326.67ms, mfu 2.86%\n",
            "iter 3090: loss 0.3340, time 325.38ms, mfu 2.87%\n",
            "iter 3100: loss 0.3178, time 329.60ms, mfu 2.88%\n",
            "iter 3110: loss 0.3308, time 325.18ms, mfu 2.90%\n",
            "iter 3120: loss 0.3123, time 330.74ms, mfu 2.90%\n",
            "iter 3130: loss 0.3174, time 327.03ms, mfu 2.91%\n",
            "iter 3140: loss 0.3273, time 328.45ms, mfu 2.92%\n",
            "iter 3150: loss 0.3237, time 328.13ms, mfu 2.93%\n",
            "iter 3160: loss 0.3328, time 326.17ms, mfu 2.93%\n",
            "iter 3170: loss 0.2977, time 329.17ms, mfu 2.94%\n",
            "iter 3180: loss 0.3069, time 326.37ms, mfu 2.95%\n",
            "iter 3190: loss 0.3072, time 322.76ms, mfu 2.95%\n",
            "iter 3200: loss 0.3257, time 326.20ms, mfu 2.96%\n",
            "iter 3210: loss 0.3064, time 327.17ms, mfu 2.96%\n",
            "iter 3220: loss 0.3015, time 325.92ms, mfu 2.97%\n",
            "iter 3230: loss 0.2977, time 327.29ms, mfu 2.97%\n",
            "iter 3240: loss 0.3111, time 327.05ms, mfu 2.97%\n",
            "step 3250: train loss 0.1062, val loss 9.0461\n",
            "iter 3250: loss 0.2757, time 47112.60ms, mfu 2.68%\n",
            "iter 3260: loss 0.2997, time 331.05ms, mfu 2.71%\n",
            "iter 3270: loss 0.3075, time 327.34ms, mfu 2.74%\n",
            "iter 3280: loss 0.3014, time 326.64ms, mfu 2.76%\n",
            "iter 3290: loss 0.2783, time 326.68ms, mfu 2.79%\n",
            "iter 3300: loss 0.3032, time 327.48ms, mfu 2.81%\n",
            "iter 3310: loss 0.2959, time 325.51ms, mfu 2.83%\n",
            "iter 3320: loss 0.3069, time 328.25ms, mfu 2.84%\n",
            "iter 3330: loss 0.2939, time 330.63ms, mfu 2.86%\n",
            "iter 3340: loss 0.2935, time 330.82ms, mfu 2.87%\n",
            "iter 3350: loss 0.2915, time 327.17ms, mfu 2.88%\n",
            "iter 3360: loss 0.2878, time 324.67ms, mfu 2.89%\n",
            "iter 3370: loss 0.2819, time 325.35ms, mfu 2.91%\n",
            "iter 3380: loss 0.2938, time 329.33ms, mfu 2.91%\n",
            "iter 3390: loss 0.2894, time 325.35ms, mfu 2.92%\n",
            "iter 3400: loss 0.2904, time 327.05ms, mfu 2.93%\n",
            "iter 3410: loss 0.2898, time 331.38ms, mfu 2.93%\n",
            "iter 3420: loss 0.2832, time 325.11ms, mfu 2.94%\n",
            "iter 3430: loss 0.2747, time 326.59ms, mfu 2.95%\n",
            "iter 3440: loss 0.2821, time 328.92ms, mfu 2.95%\n",
            "iter 3450: loss 0.2766, time 329.16ms, mfu 2.95%\n",
            "iter 3460: loss 0.2581, time 328.13ms, mfu 2.96%\n",
            "iter 3470: loss 0.2714, time 327.58ms, mfu 2.96%\n",
            "iter 3480: loss 0.2659, time 329.02ms, mfu 2.96%\n",
            "iter 3490: loss 0.2687, time 332.61ms, mfu 2.96%\n",
            "step 3500: train loss 0.1000, val loss 9.1434\n",
            "iter 3500: loss 0.2850, time 47168.09ms, mfu 2.67%\n",
            "iter 3510: loss 0.2624, time 330.95ms, mfu 2.70%\n",
            "iter 3520: loss 0.2672, time 329.63ms, mfu 2.72%\n",
            "iter 3530: loss 0.2765, time 326.45ms, mfu 2.75%\n",
            "iter 3540: loss 0.2778, time 327.11ms, mfu 2.78%\n",
            "iter 3550: loss 0.2780, time 328.75ms, mfu 2.80%\n",
            "iter 3560: loss 0.2704, time 326.21ms, mfu 2.82%\n",
            "iter 3570: loss 0.2629, time 326.74ms, mfu 2.84%\n",
            "iter 3580: loss 0.2546, time 324.14ms, mfu 2.86%\n",
            "iter 3590: loss 0.2506, time 330.31ms, mfu 2.87%\n",
            "iter 3600: loss 0.2707, time 325.91ms, mfu 2.88%\n",
            "iter 3610: loss 0.2700, time 326.84ms, mfu 2.89%\n",
            "iter 3620: loss 0.2636, time 326.95ms, mfu 2.90%\n",
            "iter 3630: loss 0.2679, time 329.85ms, mfu 2.91%\n",
            "iter 3640: loss 0.2739, time 328.01ms, mfu 2.92%\n",
            "iter 3650: loss 0.2614, time 327.98ms, mfu 2.93%\n",
            "iter 3660: loss 0.2687, time 330.63ms, mfu 2.93%\n",
            "iter 3670: loss 0.2570, time 325.72ms, mfu 2.94%\n",
            "iter 3680: loss 0.2811, time 330.15ms, mfu 2.94%\n",
            "iter 3690: loss 0.2622, time 329.43ms, mfu 2.94%\n",
            "iter 3700: loss 0.2516, time 325.93ms, mfu 2.95%\n",
            "iter 3710: loss 0.2649, time 332.26ms, mfu 2.95%\n",
            "iter 3720: loss 0.2625, time 329.66ms, mfu 2.95%\n",
            "iter 3730: loss 0.2485, time 325.89ms, mfu 2.96%\n",
            "iter 3740: loss 0.2592, time 325.57ms, mfu 2.96%\n",
            "step 3750: train loss 0.0959, val loss 9.3136\n",
            "iter 3750: loss 0.2502, time 47061.41ms, mfu 2.67%\n",
            "iter 3760: loss 0.2638, time 327.66ms, mfu 2.70%\n",
            "iter 3770: loss 0.2687, time 325.08ms, mfu 2.73%\n",
            "iter 3780: loss 0.2421, time 327.47ms, mfu 2.76%\n",
            "iter 3790: loss 0.2515, time 327.02ms, mfu 2.78%\n",
            "iter 3800: loss 0.2400, time 326.89ms, mfu 2.80%\n",
            "iter 3810: loss 0.2485, time 330.04ms, mfu 2.82%\n",
            "iter 3820: loss 0.2379, time 326.50ms, mfu 2.84%\n",
            "iter 3830: loss 0.2434, time 328.95ms, mfu 2.85%\n",
            "iter 3840: loss 0.2430, time 332.06ms, mfu 2.86%\n",
            "iter 3850: loss 0.2495, time 326.33ms, mfu 2.88%\n",
            "iter 3860: loss 0.2402, time 324.13ms, mfu 2.89%\n",
            "iter 3870: loss 0.2419, time 323.69ms, mfu 2.91%\n",
            "iter 3880: loss 0.2429, time 327.64ms, mfu 2.91%\n",
            "iter 3890: loss 0.2460, time 325.22ms, mfu 2.92%\n",
            "iter 3900: loss 0.2490, time 326.29ms, mfu 2.93%\n",
            "iter 3910: loss 0.2301, time 327.82ms, mfu 2.94%\n",
            "iter 3920: loss 0.2564, time 326.00ms, mfu 2.95%\n",
            "iter 3930: loss 0.2264, time 325.52ms, mfu 2.95%\n",
            "iter 3940: loss 0.2386, time 331.00ms, mfu 2.95%\n",
            "iter 3950: loss 0.2342, time 328.07ms, mfu 2.96%\n",
            "iter 3960: loss 0.2367, time 325.50ms, mfu 2.96%\n",
            "iter 3970: loss 0.2312, time 329.94ms, mfu 2.96%\n",
            "iter 3980: loss 0.2345, time 327.02ms, mfu 2.97%\n",
            "iter 3990: loss 0.2382, time 326.26ms, mfu 2.97%\n",
            "step 4000: train loss 0.0916, val loss 9.3108\n",
            "iter 4000: loss 0.2396, time 47045.09ms, mfu 2.68%\n",
            "iter 4010: loss 0.2388, time 326.78ms, mfu 2.71%\n",
            "iter 4020: loss 0.2347, time 327.55ms, mfu 2.74%\n",
            "iter 4030: loss 0.2378, time 326.48ms, mfu 2.76%\n",
            "iter 4040: loss 0.2326, time 325.21ms, mfu 2.79%\n",
            "iter 4050: loss 0.2224, time 328.75ms, mfu 2.81%\n",
            "iter 4060: loss 0.2396, time 329.04ms, mfu 2.82%\n",
            "iter 4070: loss 0.2085, time 325.23ms, mfu 2.84%\n",
            "iter 4080: loss 0.2313, time 327.65ms, mfu 2.86%\n",
            "iter 4090: loss 0.2338, time 325.95ms, mfu 2.87%\n",
            "iter 4100: loss 0.2157, time 325.45ms, mfu 2.89%\n",
            "iter 4110: loss 0.2194, time 325.80ms, mfu 2.90%\n",
            "iter 4120: loss 0.2161, time 326.61ms, mfu 2.91%\n",
            "iter 4130: loss 0.2392, time 328.11ms, mfu 2.92%\n",
            "iter 4140: loss 0.2253, time 325.41ms, mfu 2.93%\n",
            "iter 4150: loss 0.2345, time 326.15ms, mfu 2.94%\n",
            "iter 4160: loss 0.2299, time 324.51ms, mfu 2.94%\n",
            "iter 4170: loss 0.2273, time 330.33ms, mfu 2.95%\n",
            "iter 4180: loss 0.2272, time 328.40ms, mfu 2.95%\n",
            "iter 4190: loss 0.2149, time 323.11ms, mfu 2.96%\n",
            "iter 4200: loss 0.2205, time 324.23ms, mfu 2.97%\n",
            "iter 4210: loss 0.2121, time 329.82ms, mfu 2.97%\n",
            "iter 4220: loss 0.2199, time 328.44ms, mfu 2.97%\n",
            "iter 4230: loss 0.2145, time 328.29ms, mfu 2.97%\n",
            "iter 4240: loss 0.2147, time 327.96ms, mfu 2.97%\n",
            "step 4250: train loss 0.0890, val loss 9.3885\n",
            "iter 4250: loss 0.2265, time 47012.98ms, mfu 2.68%\n",
            "iter 4260: loss 0.2070, time 325.84ms, mfu 2.71%\n",
            "iter 4270: loss 0.2242, time 330.24ms, mfu 2.74%\n",
            "iter 4280: loss 0.2149, time 329.98ms, mfu 2.76%\n",
            "iter 4290: loss 0.2079, time 325.00ms, mfu 2.79%\n",
            "iter 4300: loss 0.2268, time 329.12ms, mfu 2.80%\n",
            "iter 4310: loss 0.2135, time 326.72ms, mfu 2.82%\n",
            "iter 4320: loss 0.2068, time 327.22ms, mfu 2.84%\n",
            "iter 4330: loss 0.2072, time 329.20ms, mfu 2.86%\n",
            "iter 4340: loss 0.2134, time 328.05ms, mfu 2.87%\n",
            "iter 4350: loss 0.2057, time 326.41ms, mfu 2.88%\n",
            "iter 4360: loss 0.2176, time 328.11ms, mfu 2.89%\n",
            "iter 4370: loss 0.2151, time 330.72ms, mfu 2.90%\n",
            "iter 4380: loss 0.2039, time 328.07ms, mfu 2.91%\n",
            "iter 4390: loss 0.2081, time 326.40ms, mfu 2.92%\n",
            "iter 4400: loss 0.2137, time 328.52ms, mfu 2.92%\n",
            "iter 4410: loss 0.2183, time 327.26ms, mfu 2.93%\n",
            "iter 4420: loss 0.2121, time 327.03ms, mfu 2.94%\n",
            "iter 4430: loss 0.2129, time 329.25ms, mfu 2.94%\n",
            "iter 4440: loss 0.2169, time 327.48ms, mfu 2.95%\n",
            "iter 4450: loss 0.2134, time 330.47ms, mfu 2.95%\n",
            "iter 4460: loss 0.2067, time 327.90ms, mfu 2.95%\n",
            "iter 4470: loss 0.2020, time 325.96ms, mfu 2.96%\n",
            "iter 4480: loss 0.2002, time 330.26ms, mfu 2.96%\n",
            "iter 4490: loss 0.1950, time 328.65ms, mfu 2.96%\n",
            "step 4500: train loss 0.0863, val loss 9.4638\n",
            "iter 4500: loss 0.1966, time 47005.35ms, mfu 2.67%\n",
            "iter 4510: loss 0.2153, time 327.47ms, mfu 2.70%\n",
            "iter 4520: loss 0.2084, time 330.98ms, mfu 2.73%\n",
            "iter 4530: loss 0.2072, time 325.25ms, mfu 2.76%\n",
            "iter 4540: loss 0.1875, time 328.28ms, mfu 2.78%\n",
            "iter 4550: loss 0.2154, time 325.32ms, mfu 2.80%\n",
            "iter 4560: loss 0.2058, time 327.98ms, mfu 2.82%\n",
            "iter 4570: loss 0.2134, time 328.96ms, mfu 2.84%\n",
            "iter 4580: loss 0.2095, time 325.27ms, mfu 2.85%\n",
            "iter 4590: loss 0.1974, time 328.41ms, mfu 2.87%\n",
            "iter 4600: loss 0.2043, time 324.39ms, mfu 2.88%\n",
            "iter 4610: loss 0.2106, time 325.72ms, mfu 2.90%\n",
            "iter 4620: loss 0.2055, time 331.09ms, mfu 2.90%\n",
            "iter 4630: loss 0.2044, time 327.26ms, mfu 2.91%\n",
            "iter 4640: loss 0.2103, time 328.37ms, mfu 2.92%\n",
            "iter 4650: loss 0.2030, time 327.54ms, mfu 2.93%\n",
            "iter 4660: loss 0.2005, time 327.59ms, mfu 2.93%\n",
            "iter 4670: loss 0.2091, time 325.27ms, mfu 2.94%\n",
            "iter 4680: loss 0.2018, time 327.00ms, mfu 2.95%\n",
            "iter 4690: loss 0.2036, time 328.39ms, mfu 2.95%\n",
            "iter 4700: loss 0.2118, time 326.05ms, mfu 2.96%\n",
            "iter 4710: loss 0.2054, time 327.97ms, mfu 2.96%\n",
            "iter 4720: loss 0.2057, time 326.52ms, mfu 2.96%\n",
            "iter 4730: loss 0.2055, time 326.93ms, mfu 2.97%\n",
            "iter 4740: loss 0.2030, time 329.06ms, mfu 2.97%\n",
            "step 4750: train loss 0.0842, val loss 9.5046\n",
            "iter 4750: loss 0.1996, time 46993.33ms, mfu 2.67%\n",
            "iter 4760: loss 0.1909, time 329.65ms, mfu 2.70%\n",
            "iter 4770: loss 0.2037, time 327.45ms, mfu 2.73%\n",
            "iter 4780: loss 0.1968, time 326.73ms, mfu 2.76%\n",
            "iter 4790: loss 0.2001, time 325.53ms, mfu 2.79%\n",
            "iter 4800: loss 0.2066, time 327.84ms, mfu 2.81%\n",
            "iter 4810: loss 0.2095, time 325.02ms, mfu 2.83%\n",
            "iter 4820: loss 0.2071, time 326.06ms, mfu 2.84%\n",
            "iter 4830: loss 0.1856, time 327.57ms, mfu 2.86%\n",
            "iter 4840: loss 0.1959, time 326.27ms, mfu 2.87%\n",
            "iter 4850: loss 0.1992, time 326.85ms, mfu 2.89%\n",
            "iter 4860: loss 0.2035, time 325.68ms, mfu 2.90%\n",
            "iter 4870: loss 0.1856, time 328.99ms, mfu 2.91%\n",
            "iter 4880: loss 0.1951, time 326.17ms, mfu 2.92%\n",
            "iter 4890: loss 0.1933, time 329.18ms, mfu 2.92%\n",
            "iter 4900: loss 0.2009, time 328.70ms, mfu 2.93%\n",
            "iter 4910: loss 0.1819, time 330.05ms, mfu 2.93%\n",
            "iter 4920: loss 0.1943, time 327.95ms, mfu 2.94%\n",
            "iter 4930: loss 0.1888, time 326.52ms, mfu 2.95%\n",
            "iter 4940: loss 0.1796, time 330.90ms, mfu 2.95%\n",
            "iter 4950: loss 0.1978, time 327.16ms, mfu 2.95%\n",
            "iter 4960: loss 0.1919, time 326.02ms, mfu 2.96%\n",
            "iter 4970: loss 0.1875, time 329.94ms, mfu 2.96%\n",
            "iter 4980: loss 0.1827, time 328.27ms, mfu 2.96%\n",
            "iter 4990: loss 0.2021, time 327.47ms, mfu 2.97%\n",
            "step 5000: train loss 0.0827, val loss 9.5240\n",
            "iter 5000: loss 0.1940, time 47004.23ms, mfu 2.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python sample.py \\\n",
        "    --start=\"War is what?\" \\\n",
        "    --num_samples=1 --max_new_tokens=100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhH45UMnpBee",
        "outputId": "51ab92eb-d641-4d74-c7ab-3e89eea0d32a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding: start = War is what?\n",
            "Overriding: num_samples = 1\n",
            "Overriding: max_new_tokens = 100\n",
            "number of parameters: 29.94M\n",
            "No meta.pkl found, assuming GPT-2 encodings...\n",
            "War is what?\n",
            "MENENIUS:\n",
            "You have be made so?\n",
            "\n",
            "MENENIUS:\n",
            "\n",
            "No longer, that is now?\n",
            "Second Citizen:\n",
            "Did no more than but he was no.\n",
            "\n",
            "\n",
            "First Citizen:\n",
            "Nay, who speaks not:\n",
            "The heads of such power; what we could not,\n",
            "So far off with me?\n",
            "\n",
            "\n",
            "CORIOLANUS:\n",
            "IOLANUS:\n",
            "Ere I fear\n",
            "Where is the\n",
            "---------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H7uuhI9J4vtw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPsaMtWDXlUfJk/GUodlEXJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}